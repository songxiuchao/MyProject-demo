server:
  port: 8091

spring:
  application:
    name: dev02
  rabbitmq:
    host: 172.18.1.109 #192.168.136.130
    port: 5672
    username: admin
    password: 123456
    virtual-host: /
    connection-timeout: 15000
    publisher-returns: true #支持发布返回
    listener:
      simple:
        acknowledge-mode: manual
      direct:
        retry:
          enabled: true  #是否支持重试
    publisher-confirms: true  #支持发布确认
  redis:
    host: 172.18.0.139
    port: 7000
    password: test123
    timeout: 3000
    database: 0
    jedis:
      pool:
        max-active: 100
        max-wait: 3000
        max-idle: 8
        min-idle: 0
  datasource:
    username: root
    password: 123456
    url: jdbc:mysql://localhost:3306/demo?useUnicode=true&characterEncoding=utf-8&useSSL=true&serverTimezone=UTC
    type: com.alibaba.druid.pool.DruidDataSource
    driver-class-name: com.mysql.cj.jdbc.Driver
    pool:
      max-active: 100
      max-wait: 60000
      max-idle: 10
      min-idle: 1
  thymeleaf:
    prefix: classpath:/templates/
  #  kafka:
#    bootstrap-servers: 192.168.136.130:9092 #,127.0.0.2:9092,127.0.0.3:9092
#    #生产者
#    producer:
#      retries: 0
#      batch-size: 16384 #65536
#      buffer-memory: 33554432 #524288
#      key-serializer: org.apache.kafka.common.serialization.StringSerializer
#      value-serializer: org.apache.kafka.common.serialization.StringSerializer
#      properties:
#        linger.ms: 1
#    #消费者
#    consumer:
#      group-id: ideal-consumer-group
#        # earliest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
#      # latest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据
#      # none:topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常
#      auto-offset-reset: earliest
#      enable-auto-commit: true #表示在auto.commit.interval.ms时间后会自动提交topic的offset，其中auto.commit.interval.ms默认值为5000ms；
#      auto-commit-interval: 20000
#      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
#      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
#      properties:
#        session.timeout.ms: 15000
  data:
    elasticsearch:
      cluster-name: elasticsearch-cluster
      cluster-nodes: 172.18.1.244:9300
      repositories:
        enabled: true
        # MongoDB
    mongodb:
        uri: mongodb://yohi:yohi190603@172.18.0.139:27017/yohi_platform
      #uri: mongodb://root:123456@localhost:27017/demo

mybatis:
  config-location: classpath:mybatis/mybatis-config.xml
  mapper-locations: classpath:mybatis/mapper/*.xml
  type-aliases-package: com.example.demo

mybatis-plus:
  typeAliasesPackage: com.example.demo.JWTSecurity.dao
  mapper-locations: classpath:mybatis/mapper/*.xml

#netty
netty:
  server:
    url:  127.0.0.1
    port: 16001


swagger:
  enabled: true
#  title: oms-API
#  description: API文档
#  base-package:  com.example.demo
#  base-path: /**
#  exclude-path: /
#  version: @project.version@



pagehelper:
  helper-dialect: mysql
  reasonable: false
  support-methods-arguments: true
  params: count=countSql


fdfs:
  so-timeout: 1500
  connect-timeout: 600
  thumb-image:
    width: 150
    height: 120
  tracker-list: 172.18.0.139:22122

#日志
logging:
  config: classpath:logback-spring.xml
